{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11848,"databundleVersionId":862157,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/anthonytherrien/histopathologic-cancer-detection-complete?scriptVersionId=265332713\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"\n# Histopathologic Cancer Detection — TIF-Focused Notebook\n\n**Data format:** All images are `.tif`  \n**Task:** Binary classification — detect metastatic cancer in small pathology image patches  \n**Metric:** ROC AUC  \n**Author:** _Your Name_  \n**Repo URL:** _add your public GitHub repo link here_\n\n---","metadata":{"_uuid":"6fbaf687-dc3d-44bd-9b7b-51f4af14204d","_cell_guid":"44ca7d07-b945-4550-9929-e8d4964d8be7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"\n## 1) Brief description of the problem and data\n\n- All images are provided as `.tif` files  \n- Predict whether the **center 32×32 px** region of a **96×96 px** patch contains tumor tissue  \n- `train_labels.csv` has columns: `id,label` where `id` maps to `train/{id}.tif`  \n- Evaluation is **ROC AUC**","metadata":{"_uuid":"adf28e5e-0604-418e-9962-92f8101805f8","_cell_guid":"9b750bbc-f6f1-4a14-941c-36e9a3ffef80","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Imports\nimport os\nimport gc\nimport math\nimport time\nimport json\nimport random\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\n\nimport tifffile as tiff\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\n\nimport timm\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport matplotlib.pyplot as plt\n\n# Reproducibility\ndef set_seed(seed):\n    # Set python random seed\n    random.seed(seed)\n    # Set numpy random seed\n    np.random.seed(seed)\n    # Set torch random seed\n    torch.manual_seed(seed)\n    # Set CUDA deterministic flags if available\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\n# Configuration\nCFG = {\n    \"seed\": 42,\n    \"num_workers\": 4,\n    \"train_batch_size\": 128,\n    \"valid_batch_size\": 256,\n    \"img_size\": 128,\n    \"model_name\": \"efficientnet_b0\",\n    \"in_chans\": 3,\n    \"epochs\": 3,\n    \"lr\": 2e-3,\n    \"weight_decay\": 1e-5,\n    \"folds\": 3,\n    \"tta\": 4,\n    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n}\n\n# Paths\nDATA_DIR = Path(\"/kaggle/input/histopathologic-cancer-detection\")\nTRAIN_DIR = DATA_DIR / \"train\"\nTEST_DIR = DATA_DIR / \"test\"\nLABELS_CSV = DATA_DIR / \"train_labels.csv\"\nOUTPUT_DIR = Path(\"./outputs\")\n\n# Ensure output dir exists\nOUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n\n# Seed everything\nset_seed(CFG[\"seed\"])\n\n# Print config\nprint(CFG)","metadata":{"_uuid":"9b4ff90e-c0aa-49e7-be42-6e09b416f92c","_cell_guid":"6eb2f380-da9b-4540-9a9a-eddb70ef0f1a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 2) TIF utilities\n\nThe following helpers strictly load `.tif` files, handle 8/16-bit, ensure RGB output, and return `float32` arrays in `[0,1]`.","metadata":{"_uuid":"dc60955c-abbc-46b1-80e2-ac3d7f4ea6c8","_cell_guid":"335dd55c-b72b-4127-b56a-9504090baf6b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Normalize uint8/uint16 arrays to float32 [0,1]\ndef _normalize_to_float01(arr):\n    # Handle uint16\n    if arr.dtype == np.uint16:\n        # Divide by max 16-bit\n        return (arr.astype(np.float32) / 65535.0)\n    # Handle uint8\n    if arr.dtype == np.uint8:\n        # Divide by max 8-bit\n        return (arr.astype(np.float32) / 255.0)\n    # Already float\n    if np.issubdtype(arr.dtype, np.floating):\n        # Clip to range\n        arr = np.clip(arr, 0.0, 1.0).astype(np.float32)\n        # Return array\n        return arr\n    # Fallback cast\n    return arr.astype(np.float32)\n\n# Load a TIF image and ensure RGB float32 [0,1]\ndef load_tif_as_rgb_float01(path):\n    # Read with tifffile\n    arr = tiff.imread(str(path))\n    # Squeeze singleton dims\n    arr = np.squeeze(arr)\n    # If grayscale, repeat channels\n    if arr.ndim == 2:\n        # Stack to 3 channels\n        arr = np.stack([arr, arr, arr], axis=-1)\n    # If channel-first, move to HWC\n    if arr.ndim == 3 and arr.shape[0] in [1,3] and arr.shape[2] not in [1,3]:\n        # Transpose to HWC\n        arr = np.transpose(arr, (1, 2, 0))\n    # If more than 3 channels, take first 3\n    if arr.ndim == 3 and arr.shape[2] > 3:\n        # Slice first 3 channels\n        arr = arr[:, :, :3]\n    # If single channel in last dim, repeat\n    if arr.ndim == 3 and arr.shape[2] == 1:\n        # Repeat to 3 channels\n        arr = np.repeat(arr, 3, axis=2)\n    # Normalize to float [0,1]\n    arr = _normalize_to_float01(arr)\n    # Ensure shape is HWC with 3 channels\n    assert arr.ndim == 3 and arr.shape[2] == 3, f\"Expected HWC with 3 channels, got {arr.shape}\"\n    # Return array\n    return arr\n\n# Verify required TIF exists\ndef tif_exists(dir_path, image_id):\n    # Build path\n    p = Path(dir_path) / f\"{image_id}.tif\"\n    # Return existence\n    return p.exists()","metadata":{"_uuid":"e41c15bb-0ba4-470d-b761-b769ae30af72","_cell_guid":"85a8b0e7-5348-491d-acec-47500b571a45","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 3) EDA — Inspect, visualize, and clean","metadata":{"_uuid":"58c72505-16e3-4855-b6c7-42df10bae66c","_cell_guid":"0ddd096e-18bb-4bcd-a142-67dbc4df5e86","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Load labels CSV\ndf = pd.read_csv(LABELS_CSV)\n\n# Show head\nprint(df.head())\n\n# Label distribution\nprint(df.label.value_counts(normalize=True))\n\n# Validate that all referenced TIF files exist\nmissing = [i for i in df.id.values if not tif_exists(TRAIN_DIR, i)]\nprint(f\"Missing train TIF files: {len(missing)}\")\n\n# Verify shapes and dtypes on a subset\ndef inspect_tif(path):\n    # Read tif\n    arr = tiff.imread(str(path))\n    # Return info\n    return arr.shape, arr.dtype\n\n# Sample subset\nsubset_ids = df.id.sample(20, random_state=CFG[\"seed\"]).tolist()\n\n# Inspect shapes\ninspect_rows = []\nfor i in subset_ids:\n    # Build path\n    p = TRAIN_DIR / f\"{i}.tif\"\n    # Inspect array\n    shp, dt = inspect_tif(p)\n    # Append row\n    inspect_rows.append({\"id\": i, \"shape\": shp, \"dtype\": str(dt)})\n\n# Create dataframe\nshape_df = pd.DataFrame(inspect_rows)\n\n# Print sample\nprint(shape_df.head())","metadata":{"_uuid":"2fc28a4f-63f0-4953-9ff1-7518d180a617","_cell_guid":"c587b2ae-9135-411f-a8a3-1ea508feaf27","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot sample grids from TIF\ndef plot_tif_samples(ids, title):\n    # Create figure\n    plt.figure(figsize=(8, 8))\n    # Iterate over ids\n    for idx, img_id in enumerate(ids[:16]):\n        # Build path\n        p = TRAIN_DIR / f\"{img_id}.tif\"\n        # Load normalized RGB\n        im = load_tif_as_rgb_float01(p)\n        # Create subplot\n        ax = plt.subplot(4, 4, idx + 1)\n        # Show image\n        ax.imshow(im)\n        # Hide axes\n        ax.axis(\"off\")\n    # Set title\n    plt.suptitle(title)\n    # Tight layout\n    plt.tight_layout()\n    # Show plot\n    plt.show()\n\n# Select ids by class\npos_ids = df[df.label == 1].id.sample(16, random_state=CFG[\"seed\"]).tolist()\nneg_ids = df[df.label == 0].id.sample(16, random_state=CFG[\"seed\"]).tolist()\n\n# Plot samples\nplot_tif_samples(pos_ids, \"Positive samples (.tif)\")\nplot_tif_samples(neg_ids, \"Negative samples (.tif)\")","metadata":{"_uuid":"df2bd62f-8da8-43dc-8cff-e19f329e59ea","_cell_guid":"ca20f2bb-825a-4c2b-8b5b-a540dddc4527","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 4) Dataset, transforms, and dataloaders\n\nAlbumentations pipelines operate on HWC numpy arrays loaded from `.tif`.  \nAll inputs are converted to normalized RGB float32 `[0,1]` before augmentation.","metadata":{"_uuid":"561b244a-22ef-4628-ab1a-f0b16cc8c7da","_cell_guid":"f27c8fc6-875f-4466-b1bf-fc082dfad0b3","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Build augmentations\ndef build_transforms(img_size, is_train):\n    # Compose training transforms\n    if is_train:\n        # Return training transforms\n        return A.Compose([\n            A.Resize(img_size, img_size),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            A.RandomRotate90(p=0.5),\n            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15, p=0.5),\n            A.ColorJitter(p=0.2),\n            A.CoarseDropout(max_holes=4, max_height=16, max_width=16, p=0.3),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n    else:\n        # Return validation transforms\n        return A.Compose([\n            A.Resize(img_size, img_size),\n            A.Normalize(),\n            ToTensorV2(),\n        ])\n\n# Dataset class specialized for TIF\nclass PCamTIFDataset(Dataset):\n    # Initialize dataset\n    def __init__(self, df, img_dir, transforms=None):\n        # Save dataframe\n        self.df = df.reset_index(drop=True)\n        # Save image directory\n        self.img_dir = Path(img_dir)\n        # Save transforms\n        self.transforms = transforms\n\n    # Dataset length\n    def __len__(self):\n        # Return length\n        return len(self.df)\n\n    # Get item by index\n    def __getitem__(self, idx):\n        # Fetch row\n        row = self.df.iloc[idx]\n        # Build path\n        img_path = self.img_dir / f\"{row['id']}.tif\"\n        # Load as normalized RGB float\n        arr = load_tif_as_rgb_float01(img_path)\n        # Apply albumentations\n        tensor = self.transforms(image=arr)[\"image\"]\n        # Return image and label if present\n        if \"label\" in row:\n            # Return tuple\n            return tensor, torch.tensor([row[\"label\"]], dtype=torch.float32)\n        # Return image and id for test\n        return tensor, row[\"id\"]","metadata":{"_uuid":"1e9c1cc2-59d5-4995-919c-03dad5162e18","_cell_guid":"01fc3b79-8899-4804-a0ef-bf6fd77e6d72","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 5) Model architecture\n\nEfficientNet-B0 from `timm` with single-logit output.","metadata":{"_uuid":"fc983e6f-c015-4b03-990e-120596ee50a8","_cell_guid":"84502b4b-bf30-4986-8b46-6060d283683b","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Build model\ndef build_model(model_name, in_chans):\n    # Create model\n    model = timm.create_model(model_name, pretrained=True, in_chans=in_chans, num_classes=1)\n    # Return model\n    return model","metadata":{"_uuid":"e93afd7a-b66a-45c5-8d64-44e74ca8ff4f","_cell_guid":"313946ee-ed8e-4423-bc91-e641fe64d614","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 6) Training loop, validation, and cross-validation","metadata":{"_uuid":"2b773251-e994-4798-9b4b-9a0f67080ed2","_cell_guid":"9592e3c4-d441-496e-913a-113a0d074ce8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Average meter\nclass AverageMeter:\n    # Initialize\n    def __init__(self):\n        # Reset\n        self.reset()\n    # Reset fields\n    def reset(self):\n        # Reset sum\n        self.sum = 0.0\n        # Reset count\n        self.count = 0\n    # Update state\n    def update(self, val, n=1):\n        # Update sum\n        self.sum += val * n\n        # Update count\n        self.count += n\n    # Average property\n    @property\n    def avg(self):\n        # Compute average\n        return self.sum / max(1, self.count)\n\n# Validate function\ndef validate(model, loader, device):\n    # Set eval mode\n    model.eval()\n    # Initialize accumulators\n    all_logits = []\n    all_targets = []\n    # No grad context\n    with torch.no_grad():\n        # Iterate loader\n        for images, targets in loader:\n            # Move to device\n            images = images.to(device)\n            targets = targets.to(device)\n            # Forward\n            logits = model(images)\n            # Collect arrays\n            all_logits.append(logits.detach().cpu().numpy().ravel())\n            all_targets.append(targets.detach().cpu().numpy().ravel())\n    # Concatenate arrays\n    logits = np.concatenate(all_logits)\n    targets = np.concatenate(all_targets)\n    # Sigmoid to probabilities\n    probs = 1.0 / (1.0 + np.exp(-logits))\n    # Compute ROC AUC\n    auc = roc_auc_score(targets, probs)\n    # Return metric\n    return float(auc)\n\n# Train one epoch\ndef train_one_epoch(model, loader, optimizer, criterion, device):\n    # Set train mode\n    model.train()\n    # Create meter\n    loss_meter = AverageMeter()\n    # Iterate\n    for images, targets in loader:\n        # Move to device\n        images = images.to(device)\n        targets = targets.to(device)\n        # Zero grad\n        optimizer.zero_grad()\n        # Forward\n        logits = model(images)\n        # Loss\n        loss = criterion(logits, targets)\n        # Backward\n        loss.backward()\n        # Step\n        optimizer.step()\n        # Update loss\n        loss_meter.update(loss.item(), images.size(0))\n    # Return avg loss\n    return loss_meter.avg","metadata":{"_uuid":"4a50e929-3fa2-4fc9-a304-2f2c94944e36","_cell_guid":"73b574e9-0d91-4d3c-8083-07432b5ed059","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Cross-validation driver\ndef run_training(df, cfg):\n    # Initialize fold AUCs\n    fold_aucs = []\n    # Initialize OOF\n    oof = np.zeros(len(df), dtype=np.float32)\n    # Create splitter\n    skf = StratifiedKFold(n_splits=cfg[\"folds\"], shuffle=True, random_state=cfg[\"seed\"])\n    # Enumerate folds\n    for fold, (trn_idx, val_idx) in enumerate(skf.split(df.id.values, df.label.values)):\n        # Print fold header\n        print(f\"Fold {fold + 1}/{cfg['folds']}\")\n        # Slice dataframes\n        df_trn = df.iloc[trn_idx].reset_index(drop=True)\n        df_val = df.iloc[val_idx].reset_index(drop=True)\n        # Build datasets\n        trn_ds = PCamTIFDataset(df_trn, TRAIN_DIR, build_transforms(cfg['img_size'], True))\n        val_ds = PCamTIFDataset(df_val, TRAIN_DIR, build_transforms(cfg['img_size'], False))\n        # Build loaders\n        trn_loader = DataLoader(trn_ds, batch_size=cfg['train_batch_size'], shuffle=True, num_workers=cfg['num_workers'], pin_memory=True)\n        val_loader = DataLoader(val_ds, batch_size=cfg['valid_batch_size'], shuffle=False, num_workers=cfg['num_workers'], pin_memory=True)\n        # Build model\n        model = build_model(cfg[\"model_name\"], cfg[\"in_chans\"]).to(cfg[\"device\"])\n        # Build optimizer\n        optimizer = torch.optim.AdamW(model.parameters(), lr=cfg[\"lr\"], weight_decay=cfg[\"weight_decay\"])\n        # Build loss\n        criterion = nn.BCEWithLogitsLoss()\n        # Track best\n        best_auc = -1.0\n        # Iterate epochs\n        for epoch in range(cfg[\"epochs\"]):\n            # Train epoch\n            tr_loss = train_one_epoch(model, trn_loader, optimizer, criterion, cfg[\"device\"])\n            # Validate\n            val_auc = validate(model, val_loader, cfg[\"device\"])\n            # Print progress\n            print(f\"Epoch {epoch+1}/{cfg['epochs']} - loss: {tr_loss:.4f} - val_auc: {val_auc:.4f}\")\n            # Save best\n            if val_auc > best_auc:\n                # Update best\n                best_auc = val_auc\n                # Save checkpoint\n                ckpt_path = OUTPUT_DIR / f\"model_fold{fold}.pt\"\n                torch.save(model.state_dict(), ckpt_path)\n        # Load best\n        model.load_state_dict(torch.load(OUTPUT_DIR / f\"model_fold{fold}.pt\", map_location=cfg[\"device\"]))\n        # Compute OOF predictions\n        model.eval()\n        # Collect logits\n        all_logits = []\n        # No grad\n        with torch.no_grad():\n            # Iterate val loader\n            for images, targets in val_loader:\n                # Move to device\n                images = images.to(cfg[\"device\"])\n                # Predict\n                logits = model(images)\n                # Append\n                all_logits.append(logits.detach().cpu().numpy().ravel())\n        # Concatenate logits\n        logits = np.concatenate(all_logits)\n        # To probabilities\n        probs = 1.0 / (1.0 + np.exp(-logits))\n        # Store OOF\n        oof[val_idx] = probs\n        # Append best\n        fold_aucs.append(best_auc)\n        # Free memory\n        del model, trn_loader, val_loader, trn_ds, val_ds, optimizer\n        gc.collect()\n        torch.cuda.empty_cache()\n    # Compute OOF AUC\n    oof_auc = roc_auc_score(df.label.values, oof)\n    # Save OOF\n    pd.DataFrame({\"id\": df.id.values, \"oof\": oof}).to_csv(OUTPUT_DIR / \"oof.csv\", index=False)\n    # Return metrics\n    return fold_aucs, oof_auc","metadata":{"_uuid":"b01c83e7-3a95-45e0-b7a5-0861f0a8942f","_cell_guid":"01411711-a32e-434d-bd75-edb98bbfd61a","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 7) Inference on TIF test set and submission","metadata":{"_uuid":"288e067d-99ca-40bb-a3dc-13ec9390d490","_cell_guid":"61e8a2af-c45c-4970-bfde-3fb66a0abaf7","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"# Test-time augmentation\ndef apply_tta(images, tta):\n    # Return list when no TTA\n    if tta <= 1:\n        # Return single\n        return [images]\n    # Create variants\n    images_list = [images]\n    images_list.append(torch.flip(images, dims=[3]))\n    images_list.append(torch.flip(images, dims=[2]))\n    images_list.append(torch.flip(images, dims=[2,3]))\n    # Return limited list\n    return images_list[:tta]\n\n# Predict on test set of TIFs\ndef predict_test(models, cfg):\n    # Gather test ids from TIF files\n    test_ids = sorted([p.stem for p in Path(TEST_DIR).glob(\"*.tif\")])\n    # Build dataframe\n    test_df = pd.DataFrame({\"id\": test_ids})\n    # Build dataset and loader\n    test_ds = PCamTIFDataset(test_df, TEST_DIR, build_transforms(cfg[\"img_size\"], False))\n    test_loader = DataLoader(test_ds, batch_size=cfg[\"valid_batch_size\"], shuffle=False, num_workers=cfg[\"num_workers\"], pin_memory=True)\n    # Initialize predictions\n    preds = []\n    # No grad context\n    with torch.no_grad():\n        # Iterate batches\n        for images, _ids in test_loader:\n            # Move to device\n            images = images.to(cfg[\"device\"])\n            # Initialize accumulator\n            logits_accum = torch.zeros(images.size(0), 1, device=cfg[\"device\"])\n            # Iterate models\n            for model in models:\n                # Set eval\n                model.eval()\n                # Iterate TTA variants\n                for img_batch in apply_tta(images, cfg[\"tta\"]):\n                    # Forward\n                    logits = model(img_batch)\n                    # Accumulate\n                    logits_accum += logits\n            # Average logits\n            logits_accum = logits_accum / (len(models) * max(1, cfg[\"tta\"]))\n            # Convert to probs\n            probs = torch.sigmoid(logits_accum).squeeze(1).detach().cpu().numpy()\n            # Extend list\n            preds.extend(probs.tolist())\n    # Build submission\n    sub = pd.DataFrame({\"id\": test_df[\"id\"], \"label\": preds})\n    # Save submission\n    sub_path = OUTPUT_DIR / \"submission.csv\"\n    sub.to_csv(sub_path, index=False)\n    # Return path\n    return sub_path","metadata":{"_uuid":"daf98a1c-c649-49b9-a375-4773cc2cf958","_cell_guid":"5540aff8-2b84-4672-89f2-345a3fcc489f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 8) Run training and create submission","metadata":{"_uuid":"4bee8965-81ed-4642-8d96-7d7c450ae0cc","_cell_guid":"98fae84c-5d83-4889-9e09-57fa7380b253","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"def main():\n    # Load labels\n    df = pd.read_csv(LABELS_CSV)\n    # Validate all referenced TIFs exist\n    assert all((TRAIN_DIR / f\"{i}.tif\").exists() for i in df.id.values), \"One or more train TIFs are missing\"\n    # Run CV training\n    fold_aucs, oof_auc = run_training(df, CFG)\n    # Print metrics\n    print(f\"Fold AUCs: {fold_aucs}\")\n    print(f\"OOF AUC: {oof_auc:.4f}\")\n    # Load best models\n    models = []\n    for fold in range(CFG[\"folds\"]):\n        # Build model\n        m = build_model(CFG[\"model_name\"], CFG[\"in_chans\"]).to(CFG[\"device\"])\n        # Load weights\n        m.load_state_dict(torch.load(OUTPUT_DIR / f\"model_fold{fold}.pt\", map_location=CFG[\"device\"]))\n        # Append\n        models.append(m)\n    # Predict test and write submission\n    sub_path = predict_test(models, CFG)\n    # Print path\n    print(f\"Saved submission to: {sub_path}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"_uuid":"d8c0003b-e84f-416e-8f6c-92be88baaf1e","_cell_guid":"4c4c96b8-13f3-418f-9cdd-e7f0a95cc861","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"\n## 9) Results and analysis\n\n- Report per-fold AUC and OOF AUC  \n- Include an experiments table with architecture, augmentations, LR, epochs, AUC  \n- Discuss what helped and what did not  \n- Summarize hyperparameter tuning","metadata":{"_uuid":"fbab4f2d-f4cc-4e45-8199-67c72b59f472","_cell_guid":"22aa6eaf-27bc-4d0f-b189-565e3c32078c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"\n## 10) Conclusion\n\n- Summarize key findings and performance  \n- Note limitations  \n- Future improvements:\n    - Larger backbones or higher input size\n    - Stain-aware augmentation or normalization\n    - Focal loss or class-weighting\n    - Pseudo-labeling\n    - Ensembling","metadata":{"_uuid":"7e1e4944-58ed-413c-b232-9db856239d5f","_cell_guid":"db2bbac8-543b-4ced-8a5f-8667cffbdaf9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"markdown","source":"\n## 11) Kaggle submission & deliverables checklist\n\n- Generate `outputs/submission.csv`  \n- Submit on Kaggle and capture a leaderboard screenshot  \n- Publish a public GitHub repo with:\n    - This notebook\n    - `README.md` for setup and results\n    - `requirements.txt`\n- Link the GitHub repo inside the notebook","metadata":{"_uuid":"4f277cbf-0670-476a-a50d-7dca3f51cb7e","_cell_guid":"b8676c84-30f4-4936-a2d5-e670adf911b4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}}]}